"""
CONTRÃ”LEUR - Page d'extraction KOSMOS
Architecture MVC
GÃ¨re la logique de la page d'extraction (lecture, navigation, outils)
"""
import datetime
import csv 
import json
import sys
import cv2
import numpy as np
import subprocess
from pathlib import Path
from PyQt6.QtCore import QObject, pyqtSignal
from PyQt6.QtGui import QPixmap
from PyQt6.QtWidgets import QApplication

# Ajout du chemin racine pour les imports
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from models.app_model import UnderwaterFilters

class ExtractionKosmosController(QObject):
    """
    ContrÃ´leur pour la page d'extraction.
    GÃ¨re les interactions entre la vue ExtractionView et le modÃ¨le ApplicationModel.
    """
    
    # Signal pour demander Ã  l'application principale de changer de page
    navigation_demandee = pyqtSignal(str)
    
    def __init__(self, model, parent=None):
        super().__init__(parent)
        self.model = model
        self.view = None # Sera dÃ©fini lors de l'initialisation de la vue
        
        # Ã‰tat local pour les corrections
        self.brightness = 0
        self.contrast = 0
        self.pending_capture_name = None # Pour stocker le nom de la capture
        
    def set_view(self, view):
        """Associe la vue Ã  ce contrÃ´leur"""
        self.view = view
        
        # Afficher la premiÃ¨re vidÃ©o conservÃ©e au lancement de la page Extraction
        if self.view and hasattr(self.view, 'view_shown'):
            self.view.view_shown.connect(self.load_first_video)

    def load_first_video(self):
        """
        Charge la premiÃ¨re vidÃ©o marquÃ©e comme "conservÃ©e" dans le lecteur.
        Cette mÃ©thode est appelÃ©e lorsque la page d'extraction devient visible.
        """
        if not self.model.campagne_courante:
            return

        videos_conservees = self.model.campagne_courante.obtenir_videos_conservees()
        if videos_conservees:
            premiere_video = videos_conservees[0]
            print(f"ğŸ“¹ Chargement de la premiÃ¨re vidÃ©o conservÃ©e : {premiere_video.nom}")
            self.charger_video_dans_lecteur(premiere_video)

    def load_initial_data(self):
        """
        Charge les donnÃ©es initiales dans la vue au dÃ©marrage.
        RÃ©cupÃ¨re la liste des vidÃ©os du modÃ¨le et met Ã  jour l'explorateur.
        """
        if not self.view:
            return

        # RÃ©cupÃ©rer les vidÃ©os de la campagne courante
        videos = self.model.obtenir_videos()
        
        # Formater pour la vue (l'explorateur attend une liste de dicts)
        videos_data = []
        for vid in videos:
            # GÃ©nÃ©rer la miniature de la vidÃ©o
            thumbnail_pixmap = self._generer_miniature_video(vid.chemin)
            color = "#00CBA9" if vid.est_conservee else "#FF6B6B"
            videos_data.append({
                'name': vid.nom,
                'thumbnail_pixmap': thumbnail_pixmap,
                'thumbnail_color': color
            })
            
        # Mettre Ã  jour la liste dans la vue
        self.view.update_video_list(videos_data)
        
        # Si une vidÃ©o Ã©tait dÃ©jÃ  sÃ©lectionnÃ©e dans le modÃ¨le, on la charge
        if self.model.video_selectionnee:
            self.charger_video_dans_lecteur(self.model.video_selectionnee)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # GESTION DE LA NAVIGATION ET SÃ‰LECTION
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def on_tab_changed(self, tab_name):
        """GÃ¨re le changement d'onglet via la navbar"""
        # Mapping des noms d'onglets vers les IDs de pages
        tabs_map = {
            "Fichier": "accueil",
            "Tri": "tri",
            "Extraction": "extraction",
            "Ã‰vÃ¨nements": "evenements"
        }
        if tab_name in tabs_map:
            self.navigation_demandee.emit(tabs_map[tab_name])

    def on_video_selected(self, video_name):
        """
        AppelÃ© quand une vidÃ©o est cliquÃ©e dans l'explorateur.
        Met Ã  jour le modÃ¨le et demande Ã  la vue de charger la vidÃ©o.
        """
        # Mettre Ã  jour le modÃ¨le
        video = self.model.selectionner_video(video_name)
        
        if video:
            self.charger_video_dans_lecteur(video)
        else:
            print(f"âŒ Erreur: VidÃ©o '{video_name}' non trouvÃ©e dans le modÃ¨le.")

    def charger_video_dans_lecteur(self, video):
        """PrÃ©pare les donnÃ©es de la vidÃ©o et met Ã  jour le lecteur de la vue"""
        if not self.view:
            return

        # Utilisation des mÃ©thodes du modÃ¨le (Video) pour charger les donnÃ©es
        video.charger_metadonnees_propres_json()
        video.charger_metadonnees_communes_json()
        video.charger_donnees_timeseries_csv()
        

        # PrÃ©parer les mÃ©tadonnÃ©es STATIQUES pour l'affichage.
        # On ne passe QUE le temps de dÃ©part. Le reste (temp, pression, lux)
        # sera gÃ©rÃ© dynamiquement par le lecteur Ã  partir des donnÃ©es CSV.
        metadata_display = {
            "time": video.start_time_str,
        }

        video_data = {
            'path': video.chemin,
            'metadata': metadata_display,
            'timeseries_data': video.timeseries_data 
        }

        # Demander Ã  la vue de charger cette vidÃ©o
        self.view.update_video_player(video_data)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # CONTRÃ”LE DU LECTEUR
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
    def on_play_pause(self):
        """GÃ¨re le bouton Play/Pause"""
        print("â¯ï¸ Play/Pause demandÃ©")

    def on_position_changed(self, position):
        """GÃ¨re le changement de position (slider)"""
        pass

    def on_previous_video(self):
        """Passe Ã  la vidÃ©o prÃ©cÃ©dente dans la liste"""
        self._naviguer_video(-1)

    def on_next_video(self):
        """Passe Ã  la vidÃ©o suivante dans la liste"""
        self._naviguer_video(1)

    def on_rewind(self):
        """Recule de X secondes"""
        print("âª Retour arriÃ¨re")

    def on_forward(self):
        """Avance de X secondes"""
        print("â© Avance rapide")

    def _naviguer_video(self, direction):
        """Logique interne pour changer de vidÃ©o (prÃ©cÃ©dente/suivante)"""
        videos = self.model.obtenir_videos()
        if not videos or not self.model.video_selectionnee:
            return

        current_name = self.model.video_selectionnee.nom
        
        # Trouver l'index actuel
        try:
            current_idx = -1
            for i, v in enumerate(videos):
                if v.nom == current_name:
                    current_idx = i
                    break
            
            if current_idx != -1:
                new_idx = (current_idx + direction) % len(videos)
                new_video = videos[new_idx]
                # Simuler un clic pour dÃ©clencher toute la chaÃ®ne de mise Ã  jour
                self.on_video_selected(new_video.nom)
                
        except ValueError:
            pass

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # CORRECTION D'IMAGE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def on_contrast_changed(self, value):
        """GÃ¨re le slider de contraste"""
        self.contrast = value
        if self.view and hasattr(self.view, 'video_player'):
            self.view.video_player.toggle_filter('contrast_base', UnderwaterFilters.apply_contrast_brightness, value != 0 or self.brightness != 0, contrast=self.contrast, brightness=self.brightness)

    def on_brightness_changed(self, value):
        """GÃ¨re le slider de luminositÃ©"""
        self.brightness = value
        if self.view and hasattr(self.view, 'video_player'):
            self.view.video_player.toggle_filter('contrast_base', UnderwaterFilters.apply_contrast_brightness, self.contrast != 0 or value != 0, contrast=self.contrast, brightness=self.brightness)

    def on_color_correction(self):
        """Ouvre ou applique la correction colorimÃ©trique automatique"""
        if not self.view or not hasattr(self.view, 'video_player'):
            return

        # Appliquer une chaÃ®ne de filtres par dÃ©faut
        self.view.video_player.toggle_filter('gamma', UnderwaterFilters.apply_gamma, True, gamma=1.2)
        self.view.video_player.toggle_filter('blue_correction', UnderwaterFilters.correct_blue_dominance, True, factor=0.15)
        self.view.video_player.toggle_filter('contrast', UnderwaterFilters.enhance_contrast, True, clip_limit=1.5)
        
        # Mettre Ã  jour l'Ã©tat des boutons de filtre dans le composant ImageCorrection
        self.view.image_correction.update_filter_buttons_state({
            'gamma': True,
            'blue_correction': True,
            'contrast': True,
            'denoise': self.view.video_player.is_filter_active('denoise'),
            'sharpen': self.view.video_player.is_filter_active('sharpen')
        })
        self.view.show_message("Correction automatique appliquÃ©e.", "success")

    def on_toggle_gamma(self, toggled):
        """Active ou dÃ©sactive la correction gamma."""
        if self.view and hasattr(self.view, 'video_player'):
            self.view.video_player.toggle_filter('gamma', UnderwaterFilters.apply_gamma, toggled, gamma=1.2)

    def on_toggle_contrast(self, toggled):
        """Active ou dÃ©sactive l'amÃ©lioration du contraste."""
        if self.view and hasattr(self.view, 'video_player'):
            self.view.video_player.toggle_filter('contrast', UnderwaterFilters.enhance_contrast, toggled, clip_limit=1.5)

    def on_toggle_denoise(self, toggled):
        """Active ou dÃ©sactive la rÃ©duction de bruit."""
        if self.view and hasattr(self.view, 'video_player'):
            self.view.video_player.toggle_filter('denoise', UnderwaterFilters.denoise, toggled, h=10.0)

    def on_toggle_sharpen(self, toggled):
        """Active ou dÃ©sactive le filtre de nettetÃ©."""
        if self.view and hasattr(self.view, 'video_player'):
            self.view.video_player.toggle_filter('sharpen', UnderwaterFilters.sharpen, toggled)

    def on_reset_filters(self):
        if self.view and hasattr(self.view, 'video_player'):
            self.view.video_player.reset_filters()

    def on_saturation_changed(self, value):
        """GÃ¨re le slider de saturation."""
        if self.view and hasattr(self.view, 'video_player'):
            self.view.video_player.toggle_filter('saturation', UnderwaterFilters.apply_saturation, value != 0, value=value)

    def on_hue_changed(self, value):
        """GÃ¨re le slider de teinte."""
        if self.view and hasattr(self.view, 'video_player'):
            self.view.video_player.toggle_filter('hue', UnderwaterFilters.apply_hue, value != 0, value=value)

    def on_temperature_changed(self, value):
        """GÃ¨re le slider de tempÃ©rature."""
        if self.view and hasattr(self.view, 'video_player'):
            self.view.video_player.toggle_filter('temperature', UnderwaterFilters.apply_temperature, value != 0, value=value)

    def on_curve_changed(self, lut):
        """GÃ¨re le changement de la courbe tonale."""
        if self.view and hasattr(self.view, 'video_player'):
            self.view.video_player.toggle_filter('curve', UnderwaterFilters.apply_lut, True, lut=lut)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # OUTILS D'EXTRACTION
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def on_screenshot(self):
        """Active le mode de sÃ©lection sur le lecteur vidÃ©o pour une capture d'Ã©cran."""
        if not self.model.video_selectionnee:
            self.view.show_message("Aucune vidÃ©o sÃ©lectionnÃ©e.", "warning")
            return
        
        if not self.view or not hasattr(self.view, 'video_player'):
            return
            
        # Demander le type de capture Ã  la vue
        capture_type = self.view.ask_screenshot_type()
        
        if capture_type == "full":
            # Capture de l'image complÃ¨te
            self.view.video_player.grab_frame(None)
        elif capture_type == "crop":
            # SÃ©lection d'une zone
            self.on_crop()

    def on_crop(self):
        """Active le mode de recadrage sur le lecteur vidÃ©o."""
        if self.view and hasattr(self.view, 'video_player'):
            self.view.show_message("Dessinez un rectangle sur la vidÃ©o pour capturer une zone.", "info")
            self.view.video_player.start_cropping()

    def on_crop_area_selected(self, crop_rect):
        """Slot appelÃ© lorsque l'utilisateur a sÃ©lectionnÃ© une zone Ã  capturer."""
        # Demande au lecteur de capturer l'image, en lui passant la zone Ã  recadrer.
        self.view.video_player.grab_frame(crop_rect)

    def save_captured_frame(self, frame: 'QPixmap'):
        """
        ReÃ§oit le QPixmap (dÃ©jÃ  recadrÃ© si nÃ©cessaire), demande un nom Ã  l'utilisateur,
        puis sauvegarde l'image.
        """
        if not frame:
            self.view.show_message("Impossible de capturer l'image de la vidÃ©o.", "error")
            return

        # 1. Demander le nom de la capture Ã  la vue
        capture_name = self.view.ask_capture_name()

        if not capture_name:
            self.view.show_message("Capture annulÃ©e.", "info")
            return

        self.pending_capture_name = capture_name

        # 2. DÃ©finir le chemin de sauvegarde
        workspace = self.model.campagne_courante.workspace_extraction
        if not workspace:
            self.view.show_message("Dossier d'extraction non dÃ©fini pour la campagne.", "error")
            return

        # CrÃ©er un sous-dossier "captures" pour une meilleure organisation
        captures_dir = Path(workspace) / "captures"
        captures_dir.mkdir(parents=True, exist_ok=True)

        # 3. Utiliser le nom fourni par l'utilisateur
        filename = f"{self.pending_capture_name}.png"
        save_path = captures_dir / filename

        # 4. Sauvegarder l'image (qui est dÃ©jÃ  recadrÃ©e)
        try:
            frame.save(str(save_path), "png", -1)
            self.view.show_message(f"Capture enregistrÃ©e : {filename}", "success")
            print(f"ğŸ“¸ Capture d'Ã©cran enregistrÃ©e sous : {save_path}")
        except Exception as e:
            self.view.show_message(f"Erreur lors de la sauvegarde : {e}", "error")
            print(f"âŒ Erreur sauvegarde capture : {e}")
        finally:
            # RÃ©initialiser le nom pour la prochaine capture
            self.pending_capture_name = None
            
    def _export_video_with_filters(self, source_path, output_path, start_ms, end_ms):
        """
        Exporte une portion de vidÃ©o en appliquant les filtres actifs via OpenCV
        et en encodant via FFmpeg (pipe).
        """
        import cv2
        
        cap = cv2.VideoCapture(str(source_path))
        if not cap.isOpened():
            raise Exception("Impossible d'ouvrir la vidÃ©o source")
            
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        cap.set(cv2.CAP_PROP_POS_MSEC, start_ms)
        
        duration_ms = end_ms - start_ms
        duration_s = duration_ms / 1000.0
        frames_to_process = int(duration_s * fps)
        
        start_str = str(datetime.timedelta(milliseconds=start_ms))

        cmd = [
            'ffmpeg', '-y',
            '-loglevel', 'error', # RÃ©duire la verbositÃ© pour Ã©viter le blocage du pipe stderr
            '-f', 'rawvideo',
            '-vcodec', 'rawvideo',
            '-s', f'{width}x{height}',
            '-pix_fmt', 'bgr24',
            '-r', str(fps),
            '-i', '-', 
            '-ss', start_str,
            '-i', str(source_path),
            '-t', str(duration_s),
            '-map', '0:v',
            '-map', '1:a?', # Audio optionnel
            '-c:v', 'libx264',
            '-preset', 'medium',
            '-crf', '23',
            '-c:a', 'aac',
            '-b:a', '128k',
            str(output_path)
        ]
        
        print(f"ğŸš€ Commande FFmpeg: {' '.join(cmd)}")
        
        creation_flags = 0
        if sys.platform == "win32":
            creation_flags = subprocess.CREATE_NO_WINDOW
            
        process = subprocess.Popen(
            cmd, 
            stdin=subprocess.PIPE, 
            stdout=subprocess.PIPE, 
            stderr=subprocess.PIPE,
            creationflags=creation_flags
        )
        
        filters = []
        if self.view and hasattr(self.view, 'video_player'):
            filters = self.view.video_player.active_filters
            
        print(f"ğŸ¬ Export avec filtres ({len(filters)} actifs)...")
        
        try:
            count = 0
            while count < frames_to_process:
                # Garder l'interface rÃ©active
                QApplication.processEvents()
                
                ret, frame = cap.read()
                if not ret:
                    break
                    
                # Appliquer les filtres
                if filters:
                    for name, (filter_func, kwargs) in filters.items():
                        try:
                            frame = filter_func(frame, **kwargs)
                        except Exception as e:
                            print(f"âš ï¸ Erreur filtre {name}: {e}")
                
                # Ã‰crire dans le pipe
                try:
                    process.stdin.write(frame.tobytes())
                except IOError as e:
                    print(f"âŒ Erreur Ã©criture pipe: {e}")
                    break
                    
                count += 1
                
        finally:
            cap.release()
            if process.stdin:
                process.stdin.close()
            
            # Attendre la fin du processus et rÃ©cupÃ©rer stderr
            stdout_data, stderr_data = process.communicate()
            
            if process.returncode != 0:
                stderr_output = stderr_data.decode('utf-8', errors='replace') if stderr_data else "Erreur inconnue"
                print(f"âŒ Erreur FFmpeg (code {process.returncode}): {stderr_output}")
                raise Exception(f"Erreur lors de l'encodage FFmpeg: {stderr_output[-200:]}")
            else:
                print("âœ… Export FFmpeg terminÃ© avec succÃ¨s.")

    def on_recording(self):
        """DÃ©marre/ArrÃªte l'enregistrement d'un extrait"""
        if not self.view or not self.model.video_selectionnee:
            self.view.show_message("Aucune vidÃ©o sÃ©lectionnÃ©e.", "warning")
            return

        # Calculer la position actuelle en fonction de la frame courante
        video_thread = self.view.video_player.video_thread
        if video_thread.total_frames == 0:
            self.view.show_message("La durÃ©e de la vidÃ©o est inconnue.", "error")
            return
            
        current_pos_ms = int((video_thread.current_frame / video_thread.fps) * 1000)
        duration_ms = self.view.video_player.duration

        if duration_ms == 0:
            self.view.show_message("La durÃ©e de la vidÃ©o est inconnue.", "error")
            return

        # 1. DÃ©finir la plage de sÃ©lection initiale (position actuelle + 30s)
        initial_start_ms = current_pos_ms
        initial_end_ms = min(duration_ms, current_pos_ms + 30000)

        # 2. Ouvrir la fenÃªtre d'Ã©dition via la vue
        result = self.view.open_clip_editor(
            self.model.video_selectionnee.chemin,
            initial_start_ms,
            initial_end_ms
        )

        # 3. Si l'utilisateur a validÃ©, crÃ©er l'extrait final
        if not result:
            self.view.show_message("Enregistrement annulÃ©.", "info")
            return

        try:
            rec_name, final_start_ms, final_end_ms = result
            
            final_start_str = str(datetime.timedelta(milliseconds=final_start_ms))
            final_duration_s = (final_end_ms - final_start_ms) / 1000

            recordings_dir = Path(self.model.campagne_courante.workspace_extraction) / "recordings"
            recordings_dir.mkdir(parents=True, exist_ok=True)
            final_output_path = recordings_dir / f"{rec_name}.mp4"

            self.view.show_message("Enregistrement de l'extrait final...", "info")
            
            # Utiliser la nouvelle mÃ©thode d'export avec filtres
            self._export_video_with_filters(
                self.model.video_selectionnee.chemin,
                final_output_path,
                final_start_ms,
                final_end_ms
            )
            
            self.view.show_message(f"Enregistrement '{rec_name}.mp4' sauvegardÃ© !", "success")
        except Exception as e:
            self.view.show_message(f"Erreur enregistrement final: {e}", "error")
                    
    def on_create_short(self):
        """CrÃ©e un short (extrait court format vertical ou spÃ©cifique)"""
        if not self.view or not self.model.video_selectionnee:
            self.view.show_message("Aucune vidÃ©o sÃ©lectionnÃ©e.", "warning")
            return

        # 1. Obtenir la position actuelle et la durÃ©e totale
        player = self.view.video_player
        video_thread = player.video_thread
        
        if video_thread.total_frames == 0:
            self.view.show_message("La durÃ©e de la vidÃ©o est inconnue.", "error")
            return
            
        current_pos_ms = int((video_thread.current_frame / video_thread.fps) * 1000)
        total_duration_ms = player.duration

        if total_duration_ms == 0:
            self.view.show_message("La durÃ©e de la vidÃ©o est inconnue.", "error")
            return

        # 2. Demander Ã  l'utilisateur de choisir la durÃ©e du short via la vue
        durations = ["10 secondes", "20 secondes", "30 secondes"]
        selected_duration_str = self.view.ask_short_duration(durations)

        if not selected_duration_str:
            self.view.show_message("CrÃ©ation du short annulÃ©e.", "info")
            return

        # Extraire la durÃ©e en secondes (ex: "10 secondes" -> 10)
        clip_duration_s = int(selected_duration_str.split()[0])

        # 3. Calculer les temps de dÃ©but et de fin en fonction de la durÃ©e choisie
        start_ms = max(0, current_pos_ms - (clip_duration_s * 1000 // 2))
        end_ms = min(total_duration_ms, start_ms + (clip_duration_s * 1000))
        clip_duration_s = (end_ms - start_ms) / 1000

        # Convertir en format HH:MM:SS.ms pour ffmpeg
        start_time_str = str(datetime.timedelta(milliseconds=start_ms))

        # 3. DÃ©finir les chemins temporaires
        extraction_dir = Path(self.model.campagne_courante.workspace_extraction)
        shorts_dir = extraction_dir / "shorts"
        shorts_dir.mkdir(parents=True, exist_ok=True)
        
        temp_filtered_path = shorts_dir / f"~temp_filtered.mp4"
        temp_preview_path = shorts_dir / f"~preview_temp.mp4"

        # 4. CrÃ©er un aperÃ§u accÃ©lÃ©rÃ© avec filtres
        try:
            self.view.show_message("GÃ©nÃ©ration de l'aperÃ§u avec filtres...", "info")
            
            # Ã‰tape 1: GÃ©nÃ©rer le clip filtrÃ© Ã  vitesse normale
            end_ms = start_ms + int(clip_duration_s * 1000)
            self._export_video_with_filters(
                self.model.video_selectionnee.chemin,
                temp_filtered_path,
                start_ms,
                end_ms
            )
            
            # Ã‰tape 2: AccÃ©lÃ©rer ce clip pour l'aperÃ§u (x2)
            cmd_preview = [
                'ffmpeg', '-y',
                '-i', str(temp_filtered_path),
                '-vf', 'setpts=0.5*PTS',
                '-af', 'atempo=2.0',
                '-preset', 'ultrafast',
                '-crf', '28',
                str(temp_preview_path)
            ]
            
            creation_flags = 0
            if sys.platform == "win32":
                creation_flags = subprocess.CREATE_NO_WINDOW
                
            subprocess.run(cmd_preview, check=True, capture_output=True, text=True, creationflags=creation_flags)
            
        except Exception as e:
            self.view.show_message(f"Erreur crÃ©ation aperÃ§u: {e}", "error")
            # Nettoyage en cas d'erreur
            if temp_filtered_path.exists(): temp_filtered_path.unlink()
            return

        # 5. Afficher la boÃ®te de dialogue d'aperÃ§u via la vue
        short_name = self.view.open_short_preview(str(temp_preview_path))

        try:
            # 6. Si l'utilisateur a cliquÃ© sur "Enregistrer" et entrÃ© un nom
            if short_name:
                try:
                    if not short_name:
                        self.view.show_message("Enregistrement annulÃ© : nom vide.", "warning")
                        return

                    self.view.show_message("Enregistrement du short final...", "info")
                    final_output_path = shorts_dir / f"{short_name}.mp4"
                    
                    
                    if temp_filtered_path.exists():
                        import shutil
                        shutil.move(str(temp_filtered_path), str(final_output_path))
                        self.view.show_message(f"Short '{short_name}.mp4' enregistrÃ© !", "success")
                    else:
                        raise Exception("Le fichier temporaire a disparu.")
                        
                except Exception as e:
                    self.view.show_message(f"Erreur enregistrement final: {e}", "error")

            else:
                self.view.show_message("Enregistrement annulÃ©.", "info")

        finally:
            # 7. Nettoyer les fichiers temporaires
            if temp_preview_path.exists():
                try:
                    temp_preview_path.unlink()
                except OSError: pass
            # Si le fichier filtrÃ© n'a pas Ã©tÃ© dÃ©placÃ© (ex: annulÃ©), on le supprime
            if temp_filtered_path.exists():
                try:
                    temp_filtered_path.unlink()
                except OSError: pass


    def _generer_miniature_video(self, chemin_video):
        """
        GÃ©nÃ¨re une miniature (QPixmap) Ã  partir de la premiÃ¨re frame d'une vidÃ©o.
        Args:
            chemin_video: Chemin vers le fichier vidÃ©o
        Returns:
            QPixmap ou None si Ã©chec
        """
        try:
            import cv2
            from PyQt6.QtGui import QImage, QPixmap
            cap = cv2.VideoCapture(chemin_video)
            if not cap.isOpened():
                print(f"âš ï¸ Impossible d'ouvrir la vidÃ©o : {chemin_video}")
                return None
            ret, frame = cap.read()
            cap.release()
            if not ret or frame is None:
                print(f"âš ï¸ Impossible de lire la premiÃ¨re frame : {chemin_video}")
                return None
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            height, width, channel = frame_rgb.shape
            bytes_per_line = 3 * width
            q_image = QImage(frame_rgb.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
            pixmap = QPixmap.fromImage(q_image)
            return pixmap
        except Exception as e:
            print(f"âŒ Erreur gÃ©nÃ©ration miniature pour {chemin_video}: {e}")
            return None